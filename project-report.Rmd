---
output:
  html_document: default
  pdf_document: default
---
 ---
title: "Influences of medical data on blood glucose level"
author: "Alliance of the Unshabby"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# Utility Functions used in this Report
format_decimal = function(x, k) trimws(format(round(x, k), nsmall=k))
```

## Introduction

Provide an introduction that includes:

- **Purpose of the Analysis**: Explain what you are attempting to accomplish.
- **Background Information**:
  - What is this data?
  - Where did it come from?
  - What are the variables?
  - Why is it interesting to you?
- **Objective of the Model**: Describe why you are creating a model for this data and the goal of the model.

*Note: Provide enough background so that a reader would not need to load your data to understand your report. Assume the reader is familiar with the course concepts but not your data.*

## Methods

This section contains the bulk of your work and R code. Use RMarkdown and code comments to explain your code if needed.

### Data Preparation

```{r}
file_path <- "StudentPerformanceFactors.csv"

students_data <- read.csv(file_path)

head(students_data$Exam_Score)
```

- Describe any data preparation performed on the original data before modeling.
- Include descriptions of all relevant variables.
- Explain any transformations or cleaning steps.

```{r}
# Remove empty observations
students_data = subset(students_data, students_data$Teacher_Quality != "")
students_data = subset(students_data, students_data$Parental_Education_Level != "")
students_data = subset(students_data, students_data$Distance_from_Home != "")
students_data = na.omit(students_data)

# Change Parental_Involvement to a factor variable
students_data$Parental_Involvement = as.factor(students_data$Parental_Involvement)
levels(students_data$Parental_Involvement)

# Change Access_to_Resources to a factor variable
students_data$Access_to_Resources = as.factor(students_data$Access_to_Resources)
levels(students_data$Access_to_Resources)

# Change Extracurricular_Activities to a factor variable
students_data$Extracurricular_Activities = as.factor(students_data$Extracurricular_Activities)
levels(students_data$Extracurricular_Activities)

# Change Motivation_Level to a factor variable
students_data$Motivation_Level = as.factor(students_data$Motivation_Level)
levels(students_data$Motivation_Level)

# Change Internet_Access to a factor variable
students_data$Internet_Access = as.factor(students_data$Internet_Access)
levels(students_data$Internet_Access)

# Change Family_Income to a factor variable
students_data$Family_Income = as.factor(students_data$Family_Income)
levels(students_data$Family_Income)

# Change Teacher_Quality to a factor variable
students_data$Teacher_Quality = as.factor(students_data$Teacher_Quality)
levels(students_data$Teacher_Quality)

# Change School_Type to a factor variable
students_data$School_Type = as.factor(students_data$School_Type)
levels(students_data$School_Type)

# Change Peer_Influence to a factor variable
students_data$Peer_Influence = as.factor(students_data$Peer_Influence)
levels(students_data$Peer_Influence)

# Change Learning_Disabilities to a factor variable
students_data$Learning_Disabilities = as.factor(students_data$Learning_Disabilities)
levels(students_data$Learning_Disabilities)

# Change Parental_Education_Level to a factor variable
students_data$Parental_Education_Level = as.factor(students_data$Parental_Education_Level)
levels(students_data$Parental_Education_Level)

# Change Distance_from_Home to a factor variable
students_data$Distance_from_Home = as.factor(students_data$Distance_from_Home)
levels(students_data$Distance_from_Home)

# Change Gender to a factor variable
students_data$Gender = as.factor(students_data$Gender)
levels(students_data$Gender)

# Check the size of the prepared dataset
length(students_data$Exam_Score)
```

### Modeling Process

- **Methodology**: Detail the methods you applied (e.g., multiple linear regression, dummy variables, interaction terms).
- **Decision-Making Process**:
  - Narrate your step-by-step decision-making as you adjusted the model.
  - Discuss how you attempted to validate model assumptions.
- **Diagnostics**:
  - Include residual and outlier diagnostics.
  - Discuss any transformations or model selections made.

*Your task is to use appropriate methods to find a good model that can correctly answer a question about the dataset, and then communicate your result effectively.*

We will use 10 of the predictors in the dataset to build a model. By adjusting the initial model, we will try to get a good model that can accurately predict the student's `Exam_Score` from the data of `Hours_Studied`, `Attendance`, `Parental_Involvement`, `Extracurricular_Activities`, `Sleep_Hours`, `Previous_Scores`, `Tutoring_Sessions`, `Physical_Activity`, `Parental_Education_Level`, and `Gender`.

```{r}
# Construct an initial model. We choose a additive model of 10 predictors by multiple linear regression.
initial_model = lm(Exam_Score ~ Hours_Studied + Attendance + Parental_Involvement + 
                   Extracurricular_Activities + Sleep_Hours + Previous_Scores + 
                   Tutoring_Sessions + Physical_Activity + Parental_Education_Level + Gender, 
                   data = students_data)

# Check collinearity
faraway::vif(initial_model)

# Check R^2
summary(initial_model)$r.squared
```
From the output, we can see that the variance inflation factor of all the predictors are lower than 5, so we may not worry about collinearity.

```{r warning=FALSE}
# Then, we do a AIC backward search to select a model
selected_model = step(initial_model, direction = "backward", trace = 0)

# Check the selected model
selected_model

# Check collinearity
faraway::vif(initial_model)
```
From the output of vif, we can see that we do not need to worry about collinearity for the selected model. Then, we want to check the model assumptions.

```{r}
# Construct a function for plotting
assumptions_plots = function(model, pcol = "grey", lcol = "dodgerblue") {
  par(mfrow = c(1, 2))
    plot(fitted(model), resid(model), col = pcol, pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted Versus Residuals Plot")
    abline(h = 0, col = lcol, lwd = 2)
    qqnorm(resid(model), main = "Normal Q-Q Plot", col = pcol)
    qqline(resid(model), col = lcol, lwd = 2)
}
```

```{r}
# Construct a function for calculating the LOOCV RMSE
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

```{r message=FALSE, warning=FALSE}
library(lmtest)
# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(selected_model)

# Do a Breusch-Pagan Test
bptest(selected_model)
```

For both of the plots, we can clearly see that there are some outliers in this model, which might be influential. Thus, we may need to do some adjustments for the selected model. From the Fitted Versus Residual Plot and the Breusch-Pagan Test, we can see that the mean of the residuals is roughly 0 and the spread of the residuals is roughly the same at most fitted values and the p-value for the Breusch-Pagan Test is really large, which means the linearity and constant variance assumptions are valid. However, from the Normal Q-Q plot, we can see that the points do not do not closely follow a straight line, which suggests that the normal distribution assumption is not valid.

```{r}
# Calculate the cooks distance of the selected model
cd_selected_model = cooks.distance(selected_model)

# Identify influential rows with Cook's Distance > 4/n
influential_indices = which(cd_selected_model > 4 / length(cd_selected_model))

# Remove those rows from the original dataset
students_data_cleaned = students_data[-influential_indices, ]

# Build a fixed model that excludes all the influential data (cooks distance > 4/n)
fix_model = lm(Exam_Score ~ Hours_Studied + Attendance + Parental_Involvement + 
    Extracurricular_Activities + Previous_Scores + Tutoring_Sessions + 
    Physical_Activity + Parental_Education_Level, 
    data = students_data_cleaned)
    
# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(fix_model)
```

```{r message=FALSE, warning=FALSE}
# Do a Breusch-Pagan Test
bptest(fix_model)
```
The Normal Q-Q plot is much better and clearly shows that the majority of the points closely follow a straight line, indicating that the normal distribution assumption is correct. The Fitted Versus Residual Plot may look like that mean of the residuals is approximately 0 and the spread of the residuals is roughly the same at most fitted values. However, the Breusch-Pagan test gives a pretty low p-value: `r bptest(fix_model)$p.value`, which implies that the constant variance assumption is not valid for the model after adjustments. Therefore, we need to do some transformations.

```{r}
# Do some Predictor transformations
trans_model = lm(Exam_Score ~ Hours_Studied + I(Hours_Studied ^ 2) + log(Attendance) + Parental_Involvement + 
    Extracurricular_Activities + log(Previous_Scores) + sqrt(Tutoring_Sessions) + 
    Physical_Activity + I(Physical_Activity ^ 2) + Parental_Education_Level, 
    data = students_data_cleaned)

# Do a Breusch-Pagan Test
bptest(trans_model)

# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(trans_model)
```

After the transformation, we find that the p-value of the Breusch-Pagan test is `r format_decimal(bptest(trans_model)$p.value, 4)`, which means that the test rejects the null hypothesis of constant variance for a low $\alpha$ ($p \le 0.05$), indicating that the constant variance assumption is not valid. However, from the Fitted Versus Residual Plot, we can see that the mean of the residuals is approximately 0 and the spread of the residuals is roughly the same at most fitted values, which indicates that we are close to meeting the assumption of constant variance. Moreover, the Normal Q-Q plot looks really good as the majority of the points closely follow a straight line, indicating that the normal distribution assumption is almost correct. Therefore, while this transformed model shows promising results and we are on the right track, further transformations, such as using Box-Cox, will be performed to address the remaining issues.


```{r}
library(MASS)
boxcox(trans_model, lambda = seq(0.2, 0.9, 0.01))
```

The **Box-Cox plot** demonstrates that a response transformation could significantly enhance the model's fit. The estimated value of $\lambda$ is approximately **0.6**, which falls within the 95% confidence interval of $0.3$ to $0.8$. After evaluating several values within this interval, $\lambda = 0.6$ was selected because it yielded the largest Breusch-Pagan test p-value, indicating the best stabilization of variance. This transformation is expected to address heteroscedasticity and improve adherence to the model's assumptions.


```{r}
# Add Box-Cox transformation to Response
trans_model_cox = lm(
  (((Exam_Score ^ 0.6) - 1) / 0.6) ~ Hours_Studied + I(Hours_Studied ^ 2) + log(Attendance) + Parental_Involvement + Extracurricular_Activities + log(Previous_Scores) + sqrt(Tutoring_Sessions) + Physical_Activity + I(Physical_Activity ^ 2) + Parental_Education_Level,
  data = students_data_cleaned
)

# Do a Breusch-Pagan Test
bptest(trans_model_cox)

# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(trans_model_cox)
```

After applying the Box-Cox transformation with $\lambda = 0.6$, the Breusch-Pagan test yielded a p-value of `r format_decimal(bptest(trans_model_cox)$p.value, 4)`, indicating that the test fails to reject the null hypothesis of constant variance. This confirms that the constant variance assumption is now valid. The **Fitted Versus Residual Plot** shows that the residuals have a mean approximately equal to 0, with a consistent spread across the fitted values, supporting the linearity and constant variance assumptions. Additionally, the **Normal Q-Q plot** demonstrates that the residuals closely follow the diagonal line, confirming that the normality assumption is satisfied. These results validate the final model with the Box-Cox transformation, making it suitable for interpretation and inference.


## Results

- Present numerical and graphical summaries of your results.
- Report the final model you have chosen.
- Provide evidence that your final choice of model is a good one.
- Include relevant tables, charts, or figures, and discuss them in the text.

### Final Model

The final model selected for predicting exam scores incorporates key predictors, including transformed terms for Hours_Studied, Attendance, Previous_Scores, and Physical_Activity, as well as categorical variables like Parental_Involvement and Parental_Education_Level. The model equation is as follows:
$$
\begin{aligned}
\frac{\text{Exam_Score}^{0.6} - 1}{0.6} = & \ \beta_0 + \beta_1 \cdot \text{Hours_Studied} + \beta_2 \cdot \text{Hours_Studied}^2 + \beta_3 \cdot \log(\text{Attendance}) \\
& + \beta_4 \cdot \text{Parental_Involvement}_{\text{Low}} + \beta_5 \cdot \text{Parental_Involvement}_{\text{Medium}} + \beta_6 \cdot \text{Extracurricular_Activities} \\
& + \beta_7 \cdot \log(\text{Previous_Scores}) + \beta_8 \cdot \sqrt{\text{Tutoring_Sessions}} + \beta_9 \cdot \text{Physical_Activity} \\
& + \beta_{10} \cdot \text{Physical_Activity}^2 + \beta_{11} \cdot \text{Parental_Education_Level}_{\text{High_School}} \\
& + \beta_{12} \cdot \text{Parental_Education_Level}_{\text{Postgraduate}} + \epsilon
\end{aligned}
$$

### Model Performance

```{r}
# LOOCV RMSE
loocv_rmse = calc_loocv_rmse(trans_model_cox)

# Extract adjusted R^2 from model summary
adjusted_r2 = summary(trans_model_cox)$adj.r.squared

# RMSE
rmse = sqrt(mean(resid(trans_model_cox)^2))
```

The final model demonstrates strong predictive capability with an adjusted $R^2$ of `r format_decimal(adjusted_r2, 4)`, indicating that it explains the majority of the variability in the exam scores. Additionally, the Root Mean Squared Error (RMSE) of the model is `r format_decimal(rmse, 4)`, and the Leave-One-Out Cross-Validation RMSE (LOOCV RMSE) is `r format_decimal(loocv_rmse, 4)`. The similarity between the RMSE and LOOCV RMSE values confirms that the model generalizes well to unseen data, making it suitable for prediction tasks.

### Predicted vs Actual Plot

```{r}
# Generate predicted values
predicted_values = predict(trans_model_cox)

# Reverse the Box-Cox transformation
original_scale_predictions = (predicted_values * 0.6 + 1)^(1 / 0.6)

# Create the plot
plot(students_data_cleaned$Exam_Score, original_scale_predictions,
     xlab = "Actual Exam Scores",
     ylab = "Predicted Exam Scores",
     main = "Predicted vs Actual Exam Scores",
     pch = 16, col = "blue")
abline(0, 1, col = "red", lwd = 2)
```

The points in the **Predicted vs Actual Exam Scores** plot generally cluster along the red 45-degree line, indicating a strong agreement between the model's predictions and the actual exam scores. This suggests that the model captures the underlying relationship in the data effectively.

### Residuals vs Fitted plot

```{r}
# Residual plot
plot(fitted(trans_model_cox), resid(trans_model_cox),
     xlab = "Fitted Values",
     ylab = "Residuals",
     main = "Residuals vs Fitted",
     pch = 16, col = "blue")
abline(h = 0, col = "red", lwd = 2) # Add a horizontal line at 0
```

The **Residuals vs Fitted plot** indicates that the residuals are evenly distributed around zero, with no discernible patterns or systematic bias. This suggests that the model assumptions of linearity and independence are valid. While there is a slight decrease in variance at the extremes, this is likely due to the smaller number of data points at very low and very high exam scores, which are less common in the dataset. Overall, the model demonstrates good reliability across the range of predicted values.

### Breusch-Pagan Test

```{r}
# Perform the Breusch-Pagan test
library(lmtest)
bp_test = bptest(trans_model_cox)
```

The **Breusch-Pagan Test** was conducted to statistically assess heteroscedasticity. The test yielded a p-value of `r format_decimal(bp_test$p.value, 5)`, which suggests that the residuals do exhibit constant variance. This aligns with the visual inspection of the residuals vs. fitted plot, further validating the reliability of the model.

### Q-Q Plot

```{r}
# Generate Q-Q plot for the residuals
qqnorm(resid(trans_model_cox), main = "Normal Q-Q Plot")
qqline(resid(trans_model_cox), col = "red", lwd = 2)
```

The **Q-Q plot** shows that most residuals closely follow the diagonal line, indicating that the residuals are approximately normally distributed. However, minor deviations at the extremes suggest some potential issues with extreme observations. These deviations are not severe and likely do not significantly impact the overall conclusions drawn from the model.

### Outliers

To address potential issues with influential data points, rows with Cook's Distance greater than $\frac{4}{n}$ were identified and removed. A total of `r length(influential_indices)` data points were excluded, representing approximately `r round((length(influential_indices) / nrow(students_data)) * 100, 2)`% of the dataset. This adjustment was relatively small, as it affected only a minor portion of the overall data. By removing these points, we improved the model's robustness without significantly altering the dataset's structure or underlying patterns.

## Discussion

#### **1. Results in the Context of the Data**
- **Key Predictors Identified**:
  - Hours studied, attendance, and parental involvement were identified as key predictors through a systematic analysis process:
    - We began with a multiple linear regression model that included all potential predictors from the dataset.
    - Using statistical techniques like backward elimination (based on AIC), we narrowed the model to the most impactful predictors that significantly contributed to explaining the variability in exam scores.
    - `Hours_Studied` emerged as a key predictor because it showed a strong and statistically significant linear relationship with exam scores (\( p < `r summary(trans_model_cox)$coefficients["Hours_Studied", "Pr(>|t|)"]` \)). Testing for quadratic effects (e.g., \( \text{Hours_Studied}^2 \)) confirmed that the relationship was sufficiently captured in its linear form.
    - `Attendance` was identified as a strong predictor after applying a logarithmic transformation to address diminishing returns at higher attendance levels. Its statistical significance (\( p = `r summary(trans_model_cox)$coefficients["log(Attendance)", "Pr(>|t|)"]` \)) highlighted its consistent impact.
    - `Parental_Involvement` was found to have a significant categorical impact, with "low" and "medium" involvement levels leading to much lower scores compared to "high" involvement.

- **Influence of Categorical Variables**:
  - Variables like `Parental Education Level` and `Extracurricular Activities` also significantly impacted performance:
    - Students with parents holding postgraduate degrees scored, on average, $`r format_decimal(summary(trans_model_cox)$coefficients["Parental_Education_LevelPostgraduate", "Estimate"], 4)`$ higher on the transformed exam score compared to those whose parents had only a high school education. This value was dynamically extracted from the regression model's coefficient for `Parental_Education_LevelPostgraduate`, representing the estimated effect of having parents with postgraduate education relative to the reference group.
    - Participation in extracurricular activities positively influenced scores (\(p = `r summary(trans_model_cox)$coefficients["Extracurricular_ActivitiesYes", "Pr(>|t|)"]`\)), likely due to improved time management and social engagement skills.

- **Statistical Refinements**:
    - Our initial model faced challenges with residual normality and variance homogeneity. For example, the Breusch-Pagan test indicated heteroscedasticity.
    - A Box-Cox transformation ($\lambda = 0.6$) successfully addressed these issues, resulting in a final model that adheres to statistical assumptions and provides reliable predictions.

---

#### **2. Transforming Data into Action**

- **Predictive Accuracy**:
  - With an adjusted $R^2$ of $`r format_decimal(adjusted_r2, 4)`$, the model explains a substantial portion of the variability in exam scores, confirming its robustness.
  - The RMSE of $r$ and LOOCV RMSE show alignment, indicating the model's capacity to generalize to new data.

- **Guidance for Improvement**:
  - **Teachers and Administrators**:
    - Policies to improve attendance, such as incentives for perfect attendance or flexible scheduling for at-risk students, could significantly improve outcomes.
    - Promoting parental engagement through workshops or regular communication with parents can address the stark performance gap associated with low parental involvement (\( `r format_decimal(summary(trans_model_cox)$coefficients["Parental_InvolvementLow", "Estimate"], 4)` \) compared to high involvement).
  - **Students**:
    - Reinforcing consistent study schedules and encouraging participation in structured extracurricular activities can lead to tangible improvements in performance.

- In practice, this model could serve as the foundation for an educational dashboard, offering real-time insights to educators and administrators. Such a system could flag students with low attendance or insufficient study hours for early intervention, while providing tailored recommendations—like increasing study hours or engaging in extracurricular activities—to enhance academic outcomes.

---

#### **3. Reflecting on the Implications of Our Findings**

- **Educational Equity**:
  - The stark differences in performance based on parental education levels and access to resources underscore the need to address **socioeconomic disparities**.
  - Scholarships, free tutoring programs, or community mentoring initiatives could help students from lower-income families compete on equal footing.

- **Policy Design**:
  - Focusing on teacher quality is crucial, as it indirectly impacts **student motivation** and **attendance**, which are key performance predictors.
  - Schools should invest in resource availability, such as digital tools or extracurricular support, to enhance learning opportunities.

- **Future Research**:
  - Exploring interactions between predictors like peer influence and school type could deepen understanding.
  - For instance, investigating how peer dynamics vary between public and private schools may reveal actionable insights about optimal learning environments.

- **Limitations to Acknowledge**:
  - The dataset predominantly focuses on quantifiable factors like hours studied, attendance, and test scores. While valuable, these only capture part of the story.
  - Adding qualitative measures such as student feedback or emotional well-being assessments could enrich the model.
  - The removal of outliers based on Cook’s Distance may have slightly limited the dataset’s representativeness, though it improved statistical validity.

## Appendix

Include supplementary materials that support your report but are not essential to the main text.

- Additional code and analysis that would clutter the main report.
- Extra figures or tables not included in the Results section.
- Any other relevant information.

*Do not simply dump code here; only include supplementary material.*

### Group Members

- Anshul Kaushik
- Desmond Fung
- Jon Green
- Kangyi Jiang

