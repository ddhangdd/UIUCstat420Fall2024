---
output:
  html_document: default
  pdf_document: default
---
 ---
title: "Influences of student data on final exam scores"
author: "Alliance of the Unshabby"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
# Utility Functions used in this Report
format_decimal = function(x, k) trimws(format(round(x, k), nsmall=k))
```

## Introduction

Provide an introduction that includes:

- **Purpose of the Analysis**: Explain what you are attempting to accomplish.
- **Background Information**:
  - What is this data?
  - Where did it come from?
  - What are the variables?
  - Why is it interesting to you?
- **Objective of the Model**: Describe why you are creating a model for this data and the goal of the model.

*Note: Provide enough background so that a reader would not need to load your data to understand your report. Assume the reader is familiar with the course concepts but not your data.*

Our main purpose with this dataset is to be able to predict student performance via exam scores from the values of the other variables in the dataset. We want to be able to see what key factors in a student's life, both at school and at home, can be correlated to higher or lower exam scores. We have some theories as to what specific factors we think will have a certain effect on scores, and we want to test those by creating models and generating plots and summaries that can showcase whether we should accept or reject the null hypothesis.

This data showcases a statistical summary of students's performance and activities done in school as well as outside factors. It looks at factors like their attendance, sleep, level of parental guidance, distance from school to home, motivation, and many more. Some factors are objective, such as distance to school and attendance, whereas other factors, such as teacher evaluation and motivation, are more subjective. Thus this dataset does have some natural bias built into it.Â 

As mentioned on the dataset Kaggle page: "The "Student Performance Factors" dataset is a synthetic dataset generated for educational and analytical purposes. The data is not sourced from any real-world institutions but is created to simulate realistic scenarios for analyzing student performance factors". Simply, this dataset is made for analysis and simulation. We will assume the data shown is very plausible to happen in real life so that our observations and tests are as authentic as possible.

List of variables: `Exam_Score` from the data of `Hours_Studied`, `Attendance`, `Parental_Involvement`, `Access_to_Resources`, `Extracurricular_Activities`, `Sleep_Hours`, `Previous_Scores`, `Motivation_Level`, `Internet_Access`, `Tutoring_Sessions`, `Family_Income`, `Teacher_Quality`, `School_Type`, `Peer_Influence`, `Physical_Activity`, `Learning_Disabilities`, `Parental_Education_Level`, `Distance_from_Home`, `Gender`, and finally `Exam_Score`.

The variables are the factors of interest that may be affecting exam scores. These range from actions done during school, like tutoring sessions, teacher quality, and previous scores, to factors involving the students home lives, like parental guidance and access to the internet and other resources. They help us gauge a student's current academic situation and their mood in regards to schoolwork and how factors outside of the classroom are impacting them.

We felt this dataset was interesting to study because, as it is around finals time right now, the results could be notable to compare to our own lives and study habits. As a student, we have subjective reasoning for how we study or do classes in ways that we think will help us perform better on final exams. It also is interesting as the dataset includes a lot of factors regarding a student's own mental mood, which usually gets overlooked in discussions about what could be affecting exam scores.

In order to figure out what variables or combinations of variables have significant correlation with exam scores, we will use a variety of different methods and models to avoid as much bias as possible. We will first set each variable to a factor variable, start with an initial model using ten of the variables, and then see the R^2 values and decide what further paths would be best.

We will use tests like Breusch-Pagan. We will also fit plots, such as fitted vs residual and Q-Q, in order to accept or reject null hypothesis predictions of certain models we believe will have a high impact on final exam scores. The purpose of creating a model is that we don't want to just look at one variable and say that is why a student is doing well or not on exams. A student's life is so complex, and the beauty of this dataset is that it covers so many different factors of the student's experience. Thus we want to make a complex model involving multiple variables to not only better reflect all of the factors but also so that we can test multiple hypotheses.

We will also make sure any model we use is actually suitable for making assumptions based on its results. We will use RMSE and LOOCV RMSE tests to ensure the model isn't just suitable for its given data and can take on more data and provide accurate results. Testing for outliers is also crucial, as although it is not inherently bad that they exist in a dataset, we need to be aware of them and do further analysis accordingly.

## Methods

This section contains the bulk of your work and R code. Use RMarkdown and code comments to explain your code if needed.

### Data Preparation

```{r}
file_path <- "StudentPerformanceFactors.csv"

students_data <- read.csv(file_path)

head(students_data$Exam_Score)
```

- Describe any data preparation performed on the original data before modeling.
- Include descriptions of all relevant variables.
- Explain any transformations or cleaning steps.

```{r}
# Remove empty observations
students_data = subset(students_data, students_data$Teacher_Quality != "")
students_data = subset(students_data, students_data$Parental_Education_Level != "")
students_data = subset(students_data, students_data$Distance_from_Home != "")
students_data = na.omit(students_data)

# Change Parental_Involvement to a factor variable
students_data$Parental_Involvement = as.factor(students_data$Parental_Involvement)
levels(students_data$Parental_Involvement)

# Change Access_to_Resources to a factor variable
students_data$Access_to_Resources = as.factor(students_data$Access_to_Resources)
levels(students_data$Access_to_Resources)

# Change Extracurricular_Activities to a factor variable
students_data$Extracurricular_Activities = as.factor(students_data$Extracurricular_Activities)
levels(students_data$Extracurricular_Activities)

# Change Motivation_Level to a factor variable
students_data$Motivation_Level = as.factor(students_data$Motivation_Level)
levels(students_data$Motivation_Level)

# Change Internet_Access to a factor variable
students_data$Internet_Access = as.factor(students_data$Internet_Access)
levels(students_data$Internet_Access)

# Change Family_Income to a factor variable
students_data$Family_Income = as.factor(students_data$Family_Income)
levels(students_data$Family_Income)

# Change Teacher_Quality to a factor variable
students_data$Teacher_Quality = as.factor(students_data$Teacher_Quality)
levels(students_data$Teacher_Quality)

# Change School_Type to a factor variable
students_data$School_Type = as.factor(students_data$School_Type)
levels(students_data$School_Type)

# Change Peer_Influence to a factor variable
students_data$Peer_Influence = as.factor(students_data$Peer_Influence)
levels(students_data$Peer_Influence)

# Change Learning_Disabilities to a factor variable
students_data$Learning_Disabilities = as.factor(students_data$Learning_Disabilities)
levels(students_data$Learning_Disabilities)

# Change Parental_Education_Level to a factor variable
students_data$Parental_Education_Level = as.factor(students_data$Parental_Education_Level)
levels(students_data$Parental_Education_Level)

# Change Distance_from_Home to a factor variable
students_data$Distance_from_Home = as.factor(students_data$Distance_from_Home)
levels(students_data$Distance_from_Home)

# Change Gender to a factor variable
students_data$Gender = as.factor(students_data$Gender)
levels(students_data$Gender)

# Check the size of the prepared dataset
length(students_data$Exam_Score)
```

### Modeling Process

- **Methodology**: Detail the methods you applied (e.g., multiple linear regression, dummy variables, interaction terms).
- **Decision-Making Process**:
  - Narrate your step-by-step decision-making as you adjusted the model.
  - Discuss how you attempted to validate model assumptions.
- **Diagnostics**:
  - Include residual and outlier diagnostics.
  - Discuss any transformations or model selections made.

*Your task is to use appropriate methods to find a good model that can correctly answer a question about the dataset, and then communicate your result effectively.*

We will use 10 of the predictors in the dataset to build a model. By adjusting the initial model, we will try to get a good model that can accurately predict the student's `Exam_Score` from the data of `Hours_Studied`, `Attendance`, `Parental_Involvement`, `Extracurricular_Activities`, `Sleep_Hours`, `Previous_Scores`, `Tutoring_Sessions`, `Physical_Activity`, `Parental_Education_Level`, and `Gender`.

```{r}
# Construct an initial model. We choose a additive model of 10 predictors by multiple linear regression.
initial_model = lm(Exam_Score ~ Hours_Studied + Attendance + Parental_Involvement + 
                   Extracurricular_Activities + Sleep_Hours + Previous_Scores + 
                   Tutoring_Sessions + Physical_Activity + Parental_Education_Level + Gender, 
                   data = students_data)

# Check collinearity
faraway::vif(initial_model)

# Check R^2
summary(initial_model)$r.squared
```
From the output, we can see that the variance inflation factor of all the predictors are lower than 5, so we may not worry about collinearity.

```{r warning=FALSE}
# Then, we do a AIC backward search to select a model
selected_model = step(initial_model, direction = "backward", trace = 0)

# Check the selected model
selected_model

# Check collinearity
faraway::vif(initial_model)
```
From the output of vif, we can see that we do not need to worry about collinearity for the selected model. Then, we want to check the model assumptions.

```{r}
# Construct a function for plotting
assumptions_plots = function(model, pcol = "grey", lcol = "dodgerblue") {
  par(mfrow = c(1, 2))
    plot(fitted(model), resid(model), col = pcol, pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted Versus Residuals Plot")
    abline(h = 0, col = lcol, lwd = 2)
    qqnorm(resid(model), main = "Normal Q-Q Plot", col = pcol)
    qqline(resid(model), col = lcol, lwd = 2)
}
```

```{r}
# Construct a function for calculating the LOOCV RMSE
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
```

```{r message=FALSE, warning=FALSE}
library(lmtest)
# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(selected_model)

# Do a Breusch-Pagan Test
bptest(selected_model)
```

For both of the plots, we can clearly see that there are some outliers in this model, which might be influential. Thus, we may need to do some adjustments for the selected model. From the Fitted Versus Residual Plot and the Breusch-Pagan Test, we can see that the mean of the residuals is roughly 0 and the spread of the residuals is roughly the same at most fitted values and the p-value for the Breusch-Pagan Test is really large, which means the linearity and constant variance assumptions are valid. However, from the Normal Q-Q plot, we can see that the points do not do not closely follow a straight line, which suggests that the normal distribution assumption is not valid.

```{r}
# Calculate the cooks distance of the selected model
cd_selected_model = cooks.distance(selected_model)

# Identify influential rows with Cook's Distance > 4/n
influential_indices = which(cd_selected_model > 4 / length(cd_selected_model))

# Remove those rows from the original dataset
students_data_cleaned = students_data[-influential_indices, ]

# Build a fixed model that excludes all the influential data (cooks distance > 4/n)
fix_model = lm(Exam_Score ~ Hours_Studied + Attendance + Parental_Involvement + 
    Extracurricular_Activities + Previous_Scores + Tutoring_Sessions + 
    Physical_Activity + Parental_Education_Level, 
    data = students_data_cleaned)
    
# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(fix_model)
```

```{r message=FALSE, warning=FALSE}
# Do a Breusch-Pagan Test
bptest(fix_model)
```
The Normal Q-Q plot is much better and clearly shows that the majority of the points closely follow a straight line, indicating that the normal distribution assumption is correct. The Fitted Versus Residual Plot may look like that mean of the residuals is approximately 0 and the spread of the residuals is roughly the same at most fitted values. However, the Breusch-Pagan test gives a pretty low p-value: `r bptest(fix_model)$p.value`, which implies that the constant variance assumption is not valid for the model after adjustments. Therefore, we need to do some transformations.

```{r}
# Do some Predictor transformations
trans_model = lm(Exam_Score ~ Hours_Studied + I(Hours_Studied ^ 2) + log(Attendance) + Parental_Involvement + 
    Extracurricular_Activities + log(Previous_Scores) + sqrt(Tutoring_Sessions) + 
    Physical_Activity + I(Physical_Activity ^ 2) + Parental_Education_Level, 
    data = students_data_cleaned)

# Do a Breusch-Pagan Test
bptest(trans_model)

# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(trans_model)
```

After the transformation, we find that the p-value of the Breusch-Pagan test is `r format_decimal(bptest(trans_model)$p.value, 4)`, which means that the test rejects the null hypothesis of constant variance for a low $\alpha$ ($p \le 0.05$), indicating that the constant variance assumption is not valid. However, from the Fitted Versus Residual Plot, we can see that the mean of the residuals is approximately 0 and the spread of the residuals is roughly the same at most fitted values, which indicates that we are close to meeting the assumption of constant variance. Moreover, the Normal Q-Q plot looks really good as the majority of the points closely follow a straight line, indicating that the normal distribution assumption is almost correct. Therefore, while this transformed model shows promising results and we are on the right track, further transformations, such as using Box-Cox, will be performed to address the remaining issues.


```{r}
library(MASS)
boxcox(trans_model, lambda = seq(0.2, 0.9, 0.01))
```

The **Box-Cox plot** demonstrates that a response transformation could significantly enhance the model's fit. The estimated value of $\lambda$ is approximately **0.6**, which falls within the 95% confidence interval of $0.3$ to $0.8$. After evaluating several values within this interval, $\lambda = 0.6$ was selected because it yielded the largest Breusch-Pagan test p-value, indicating the best stabilization of variance. This transformation is expected to address heteroscedasticity and improve adherence to the model's assumptions.


```{r}
# Add Box-Cox transformation to Response
trans_model_cox = lm(
  (((Exam_Score ^ 0.6) - 1) / 0.6) ~ Hours_Studied + I(Hours_Studied ^ 2) + log(Attendance) + Parental_Involvement + Extracurricular_Activities + log(Previous_Scores) + sqrt(Tutoring_Sessions) + Physical_Activity + I(Physical_Activity ^ 2) + Parental_Education_Level,
  data = students_data_cleaned
)

# Do a Breusch-Pagan Test
bptest(trans_model_cox)

# Plot the Fitted vs Residual plot and Normal Q-Q plot
assumptions_plots(trans_model_cox)
```

After applying the Box-Cox transformation with $\lambda = 0.6$, the Breusch-Pagan test yielded a p-value of `r format_decimal(bptest(trans_model_cox)$p.value, 4)`, indicating that the test fails to reject the null hypothesis of constant variance. This confirms that the constant variance assumption is now valid. The **Fitted Versus Residual Plot** shows that the residuals have a mean approximately equal to 0, with a consistent spread across the fitted values, supporting the linearity and constant variance assumptions. Additionally, the **Normal Q-Q plot** demonstrates that the residuals closely follow the diagonal line, confirming that the normality assumption is satisfied. These results validate the final model with the Box-Cox transformation, making it suitable for interpretation and inference.


## Results

- Present numerical and graphical summaries of your results.
- Report the final model you have chosen.
- Provide evidence that your final choice of model is a good one.
- Include relevant tables, charts, or figures, and discuss them in the text.

### Final Model

The final model selected for predicting exam scores incorporates key predictors, including transformed terms for Hours_Studied, Attendance, Previous_Scores, and Physical_Activity, as well as categorical variables like Parental_Involvement and Parental_Education_Level. The model equation is as follows:
$$
\begin{aligned}
\frac{\text{Exam_Score}^{0.6} - 1}{0.6} = & \ \beta_0 + \beta_1 \cdot \text{Hours_Studied} + \beta_2 \cdot \text{Hours_Studied}^2 + \beta_3 \cdot \log(\text{Attendance}) \\
& + \beta_4 \cdot \text{Parental_Involvement}_{\text{Low}} + \beta_5 \cdot \text{Parental_Involvement}_{\text{Medium}} + \beta_6 \cdot \text{Extracurricular_Activities} \\
& + \beta_7 \cdot \log(\text{Previous_Scores}) + \beta_8 \cdot \sqrt{\text{Tutoring_Sessions}} + \beta_9 \cdot \text{Physical_Activity} \\
& + \beta_{10} \cdot \text{Physical_Activity}^2 + \beta_{11} \cdot \text{Parental_Education_Level}_{\text{High_School}} \\
& + \beta_{12} \cdot \text{Parental_Education_Level}_{\text{Postgraduate}} + \epsilon
\end{aligned}
$$

### Model Performance

```{r}
# LOOCV RMSE
loocv_rmse = calc_loocv_rmse(trans_model_cox)

# Extract adjusted R^2 from model summary
adjusted_r2 = summary(trans_model_cox)$adj.r.squared

# RMSE
rmse = sqrt(mean(resid(trans_model_cox)^2))
```

The final model demonstrates strong predictive capability with an adjusted $R^2$ of `r format_decimal(adjusted_r2, 4)`, indicating that it explains the majority of the variability in the exam scores. Additionally, the Root Mean Squared Error (RMSE) of the model is `r format_decimal(rmse, 4)`, and the Leave-One-Out Cross-Validation RMSE (LOOCV RMSE) is `r format_decimal(loocv_rmse, 4)`. The similarity between the RMSE and LOOCV RMSE models confirms that the model generalizes well to unseen data, making it suitable for prediction tasks.

### Predicted vs Actual Plot

```{r}
# Generate predicted values
predicted_values = predict(trans_model_cox)

# Reverse the Box-Cox transformation
original_scale_predictions = (predicted_values * 0.6 + 1)^(1 / 0.6)

# Create the plot
plot(students_data_cleaned$Exam_Score, original_scale_predictions,
     xlab = "Actual Exam Scores",
     ylab = "Predicted Exam Scores",
     main = "Predicted vs Actual Exam Scores",
     pch = 16, col = "blue")
abline(0, 1, col = "red", lwd = 2)
```

The points in the **Predicted vs Actual Exam Scores** plot generally cluster along the red 45-degree line, indicating a strong agreement between the model's predictions and the actual exam scores. This suggests that the model captures the underlying relationship in the data effectively.

### Residuals vs Fitted plot

```{r}
# Residual plot
plot(fitted(trans_model_cox), resid(trans_model_cox),
     xlab = "Fitted Values",
     ylab = "Residuals",
     main = "Residuals vs Fitted",
     pch = 16, col = "blue")
abline(h = 0, col = "red", lwd = 2) # Add a horizontal line at 0
```

The **Residuals vs Fitted plot** indicates that the residuals are evenly distributed around zero, with no discernible patterns or systematic bias. This suggests that the model assumptions of linearity and independence are valid. While there is a slight decrease in variance at the extremes, this is likely due to the smaller number of data points at very low and very high exam scores, which are less common in the dataset. Overall, the model demonstrates good reliability across the range of predicted values.

### Breusch-Pagan Test

```{r}
# Perform the Breusch-Pagan test
library(lmtest)
bp_test = bptest(trans_model_cox)
```

The **Breusch-Pagan Test** was conducted to statistically assess heteroscedasticity. The test yielded a p-value of `r format_decimal(bp_test$p.value, 5)`, which suggests that the residuals do exhibit constant variance. This aligns with the visual inspection of the residuals vs. fitted plot, further validating the reliability of the model.

### Q-Q Plot

```{r}
# Generate Q-Q plot for the residuals
qqnorm(resid(trans_model_cox), main = "Normal Q-Q Plot")
qqline(resid(trans_model_cox), col = "red", lwd = 2)
```

The **Q-Q plot** shows that most residuals closely follow the diagonal line, indicating that the residuals are approximately normally distributed. However, minor deviations at the extremes suggest some potential issues with extreme observations. These deviations are not severe and likely do not significantly impact the overall conclusions drawn from the model.

### Outliers

To address potential issues with influential data points, rows with Cook's Distance greater than $\frac{4}{n}$ were identified and removed. A total of `r length(influential_indices)` data points were excluded, representing approximately `r round((length(influential_indices) / nrow(students_data)) * 100, 2)`% of the dataset. This adjustment was relatively small, as it affected only a minor portion of the overall data. By removing these points, we improved the model's robustness without significantly altering the dataset's structure or underlying patterns.

## Discussion

- Discuss your results in the context of the data.
- Explain how your final model is useful.
- Reflect on the implications of your findings.

## Appendix

Include supplementary materials that support your report but are not essential to the main text.

- Additional code and analysis that would clutter the main report.
- Extra figures or tables not included in the Results section.
- Any other relevant information.

*Do not simply dump code here; only include supplementary material.*

### Group Members

- Anshul Kaushik
- Desmond Fung
- Jon Green
- Kangyi Jiang

